{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9Qvh7gIVaF5Q"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM1X31rSc0tGr2fzFjXMk4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walteralzurutt/classificacion-empresas/blob/main/RBICs_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load environment and libraries"
      ],
      "metadata": {
        "id": "9Qvh7gIVaF5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install basic packages and load environments. Initialize loaders for Snowflake and Google Sheets\n",
        "\n",
        "!pip install \"sphinx==7.2.6\" > /dev/null\n",
        "\n",
        "try:  # are we running on Colab?\n",
        "  from google.colab import drive\n",
        "  from google.colab import userdata\n",
        "  colab = True\n",
        "except Exception as e:\n",
        "  colab = False\n",
        "\n",
        "if colab:\n",
        "  # install AWS CLI and dotenv\n",
        "  !pip install \"awscli==1.40.9\" \"python-dotenv==1.1.0\" \"gspread==6.2.0\" > /dev/null\n",
        "\n",
        "  import dotenv\n",
        "  from getpass import getpass\n",
        "  import os\n",
        "  import gspread\n",
        "  import base64\n",
        "  import json\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import base64\n",
        "  from datetime import timedelta\n",
        "  import sys\n",
        "\n",
        "  import logging\n",
        "  logging.basicConfig()\n",
        "  logging.getLogger('snowflake').setLevel(logging.ERROR)\n",
        "\n",
        "  import warnings\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  # mount Google Drive\n",
        "  drive.mount(\"/content/gdrive\")\n",
        "  root_dir = \"/content/gdrive/\"\n",
        "  project_drive = f\"Shareddrives/Clarity AI/05 - Product Research & Innovation/21 - Team Lifecycle/11 - SME Repository/Colab setup\"\n",
        "  home_dir = f\"{root_dir}MyDrive/Colab Notebooks/\"\n",
        "  sys.path.append(home_dir)\n",
        "\n",
        "  # Configure AWS CLI credentials\n",
        "  aws_dir = f\"{os.getenv('HOME')}/.aws\"\n",
        "  os.makedirs(aws_dir, exist_ok=True)\n",
        "\n",
        "  with open(f\"{aws_dir}/credentials\", \"wt\") as file:\n",
        "    file.write(\n",
        "  f\"\"\"[root]\n",
        "  aws_access_key_id={userdata.get(\"AWS_ACCESS_KEY_ID\")}\n",
        "  aws_secret_access_key={userdata.get(\"AWS_SECRET_ACCESS_KEY\")}\n",
        "  \"\"\"\n",
        "    )\n",
        "  with open(f\"{aws_dir}/config\", \"wt\") as file:\n",
        "    file.write(\n",
        "  f\"\"\"[profile mgmt]\n",
        "  region=eu-central-1\n",
        "  source_profile = root\n",
        "  role_arn = arn:aws:iam::913932804865:role/federateclarity\n",
        "  output=json\n",
        "  [profile federate_root]\n",
        "  region = eu-central-1\n",
        "  source_profile = root\n",
        "  role_arn = arn:aws:iam::064436394451:role/federateclarity\n",
        "  \"\"\"\n",
        "    )\n",
        "  os.environ[\"AWS_PROFILE\"] = \"mgmt\"\n",
        "  dotenv.load_dotenv(dotenv_path=f\"{home_dir}.env\")\n",
        "  !pip install \"boto3==1.38.10\" \"s3transfer>=0.12.0\" \"snowflake-connector-python==3.15.0\" \"snowflake-sqlalchemy==1.7.3\" \"numpy==2.0.2\" \"s3fs==0.4.2\" \"docutils==0.19\" \"pandas==2.2.2\" \"s3transfer>=0.12.0\" > /dev/null\n",
        "\n",
        "\n",
        "## SNOWFLAKE ##\n",
        "# Import dependencies\n",
        "import snowflake.connector as sc\n",
        "from cryptography.hazmat.backends import default_backend\n",
        "from sqlalchemy import create_engine, engine, text\n",
        "from cryptography.hazmat.primitives import serialization\n",
        "from sqlalchemy.dialects import registry\n",
        "\n",
        "# Read certificate\n",
        "try:\n",
        "  with open(\"/content/gdrive/MyDrive/Colab Notebooks/private.pem\", \"rb\") as key:\n",
        "      private_key = serialization.load_pem_private_key(\n",
        "          key.read(),\n",
        "          password=userdata.get('certificatepass').encode(),\n",
        "          backend=default_backend()\n",
        "      )\n",
        "except:\n",
        "  with open(\"/content/gdrive/MyDrive/Colab_Notebooks/private.pem\", \"rb\") as key:\n",
        "      private_key = serialization.load_pem_private_key(\n",
        "          key.read(),\n",
        "          password=userdata.get('certificatepass').encode(),\n",
        "          backend=default_backend()\n",
        "      )\n",
        "private_key_bytes = private_key.private_bytes(\n",
        "    encoding=serialization.Encoding.DER,\n",
        "    format=serialization.PrivateFormat.PKCS8,\n",
        "    encryption_algorithm=serialization.NoEncryption()\n",
        ")\n",
        "\n",
        "# Connect, create functions\n",
        "class Snowflake:\n",
        "\n",
        "  def __init__(self):\n",
        "      self.engine = engine.create_engine(\"snowflake://not@used/db\", creator=self.snow_connect)\n",
        "\n",
        "  def snow_connect(self):\n",
        "    return sc.connect(\n",
        "            user=os.getenv(\"SNOWFLAKE_USERNAME\"),\n",
        "            account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
        "            private_key=private_key_bytes,\n",
        "            role=os.getenv(\"SNOWFLAKE_ROLE\"),\n",
        "            database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
        "            warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "            )\n",
        "\n",
        "  def read_sql_query(self, query):\n",
        "    \"\"\"\n",
        "    Execute a query in Snowflake\n",
        "\n",
        "    Args:\n",
        "        query (str): SQL query to execute\n",
        "\n",
        "    Returns:\n",
        "        df (pd.DataFrame): DataFrame with the results of the query\n",
        "    \"\"\"\n",
        "    with self.engine.begin() as connection:\n",
        "        df = Snowflake().read_sql_query(text(query), con=connection)\n",
        "\n",
        "    # Make sure all column names are lowercase\n",
        "    df.columns = df.columns.str.lower()\n",
        "    return df\n",
        "\n",
        "\n",
        "## Initialize\n",
        "snowflake_connector = Snowflake()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNQbYrum7vc7",
        "outputId": "3bca3ba1-d4a1-4345-a839-cf3856953850"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pygit2 1.19.1 requires cffi>=2.0, but you have cffi 1.17.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Snowflake:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.engine = engine.create_engine(\n",
        "            \"snowflake://not@used/db\",\n",
        "            creator=self.snow_connect\n",
        "        )\n",
        "\n",
        "    def snow_connect(self):\n",
        "        return sc.connect(\n",
        "            user=os.getenv(\"SNOWFLAKE_USERNAME\"),\n",
        "            account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
        "            private_key=private_key_bytes,\n",
        "            role=os.getenv(\"SNOWFLAKE_ROLE\"),\n",
        "            database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
        "            warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "        )\n",
        "\n",
        "    def read_sql_query(self, query: str):\n",
        "        \"\"\"\n",
        "        Execute a query in Snowflake and return results as a pandas DataFrame\n",
        "        \"\"\"\n",
        "        with self.engine.begin() as connection:\n",
        "            df = pd.read_sql_query(text(query), con=connection)\n",
        "\n",
        "        # Make sure all column names are lowercase\n",
        "        df.columns = df.columns.str.lower()\n",
        "        return df"
      ],
      "metadata": {
        "id": "caeECsVWWO-N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import libraries and define functions needed to read the  registry service\n",
        "\n",
        "import requests\n",
        "import asyncio # only for async requests\n",
        "import nest_asyncio\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def extract_registry_service_data(release_tag,use_release_candidate_tag=False):\n",
        "\n",
        "  uri_base = 'https://registry-service.mgmt.clarity.ai/v1'\n",
        "\n",
        "  headers = {\"Authorization\": \"Bearer {}\".format(userdata.get('registry_service_bearer_token'))}\n",
        "\n",
        "  if use_release_candidate_tag:\n",
        "    uri = uri_base + '/tags/'+ release_candidate\n",
        "\n",
        "  else:\n",
        "    uri = uri_base + '/tags/'+ release_tag\n",
        "\n",
        "\n",
        "  params = {\n",
        "      'tenant': 'CLA'\n",
        "  }\n",
        "\n",
        "  tags = requests.get(uri, params = params, headers = headers)\n",
        "\n",
        "  tags.json()['tag']\n",
        "\n",
        "  current_tag = tags.json()['tag']\n",
        "\n",
        "  uri = uri_base + '/tags/{}'.format(current_tag)\n",
        "\n",
        "  params = {\n",
        "  }\n",
        "\n",
        "  tables = requests.get(uri, params = params, headers = headers)\n",
        "\n",
        "  tables=tables.json()['datasets']\n",
        "\n",
        "  registry_service=pd.DataFrame(tables)\n",
        "\n",
        "  registry_service_data=registry_service[['table_name','dataset_name','location','dag_owner','execution_date','module','database']].copy()\n",
        "\n",
        "  return registry_service_data\n",
        "\n",
        "\n",
        "def fetch_table_name(registry_service_data,dataset_name):\n",
        "\n",
        "  temp=registry_service_data[registry_service_data.table_name.notna()].copy()\n",
        "\n",
        "  temp=temp[temp.dataset_name == dataset_name]\n",
        "\n",
        "  temp['execution_date'] = pd.to_datetime(temp['execution_date'])\n",
        "\n",
        "  latest_date = temp['execution_date'].max()\n",
        "\n",
        "  temp=temp[temp['execution_date'] == latest_date].table_name.values\n",
        "\n",
        "  return temp[0]\n",
        "\n",
        "def fetch_table_location(registry_service_data,dataset_name):\n",
        "\n",
        "  temp=registry_service_data[registry_service_data.dataset_name == dataset_name].copy()\n",
        "\n",
        "  temp['execution_date'] = pd.to_datetime(temp['execution_date'])\n",
        "\n",
        "  latest_date = temp['execution_date'].max()\n",
        "\n",
        "  temp=temp[temp['execution_date'] == latest_date].location.values\n",
        "\n",
        "  return temp[0]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "l5Wq8kXvaPc5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Input"
      ],
      "metadata": {
        "id": "x5qpkW_MoHy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fetch data paths for a specific release tag\n",
        "\n",
        "#release_tag='RELEASE-CLA-2025-08.1'\n",
        "release_tag='RELEASE-CLA-2026-02'\n",
        "\n",
        "registry_service_data=extract_registry_service_data(release_tag)\n",
        "\n",
        "cas_path=fetch_table_name(registry_service_data,'cas_rc')"
      ],
      "metadata": {
        "id": "bwWrO5XwaWdh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the entire RBICs dataset for 2023\n",
        "\n",
        "data=Snowflake().read_sql_query(f\"\"\"\n",
        "\n",
        "select clarity_id, metric, value\n",
        "from domain_archive.{cas_path}\n",
        "where metric ilike '%rbics%pct'\n",
        "and metric_year = 2023\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "data.value=data.value.astype(float)\n",
        "\n",
        "# Cleaning up the metric names to keep only the rbics code - Removing L7 information for now\n",
        "\n",
        "data['metric'] = data['metric'].str[6:].str[:12]\n",
        "\n",
        "# Summing together rows that have the same L6 but diferent L7 into one row\n",
        "\n",
        "data=data.groupby(['clarity_id','metric']).sum('value').reset_index()"
      ],
      "metadata": {
        "id": "qaH9kD1coQ9U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbics=data.copy()\n",
        "\n",
        "for i in range(1, 7):\n",
        "    rbics[f'l{i}_id'] = rbics['metric'].str[:i*2]"
      ],
      "metadata": {
        "id": "kRTuS3cvotki"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA Tests"
      ],
      "metadata": {
        "id": "PFjK2l8m1hAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot data\n",
        "\n",
        "data_wide = data.pivot(index='clarity_id', columns='metric', values='value').fillna(0)"
      ],
      "metadata": {
        "id": "gL3920A22lLf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Set n_components as 0.95 to get enough components to explain 95% EVR\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(data_wide)\n",
        "\n",
        "print(f\"Number of components to retain 95% variance: {pca.n_components_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97Z4O10wrz2Q",
        "outputId": "7f3ddbdd-56f0-473c-e36d-c7517dbbe4e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of components to retain 95% variance: 1110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pc_index = 5  # PC1\n",
        "weights = pca.components_[pc_index]\n",
        "\n",
        "# Map to original metric names\n",
        "metric_names = data_wide.columns  # original metrics\n",
        "pc_weights = pd.Series(weights, index=metric_names)\n",
        "\n",
        "# Sort by absolute value to see strongest contributors\n",
        "pc_weights_sorted = pc_weights.abs().sort_values(ascending=False)\n",
        "print(pc_weights_sorted.head(10))  # top 10 contributing metrics for PC1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocF9DO5t90YO",
        "outputId": "a3f79927-f858-4150-9feb-c863e3810387"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metric\n",
            "302515102025    0.664025\n",
            "351015401010    0.662741\n",
            "302515151010    0.323337\n",
            "351520101010    0.086204\n",
            "302515151020    0.048484\n",
            "302515102010    0.044134\n",
            "151010102515    0.027855\n",
            "351525101010    0.024482\n",
            "351010152010    0.016862\n",
            "401525101010    0.016246\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca.components_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv6Sbp669g4_",
        "outputId": "9d8f8722-c353-4b97-f669-4cfb1f157504"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.16767308e-04, -1.90150761e-03, -1.98655930e-04, ...,\n",
              "        -3.67899037e-05, -4.74906686e-04, -8.70325473e-04],\n",
              "       [-3.51473680e-04, -2.03301539e-03, -1.99397818e-04, ...,\n",
              "        -3.33586033e-05, -4.58417352e-04, -5.55121224e-04],\n",
              "       [-3.42301485e-04, -1.59468807e-03, -1.87594289e-04, ...,\n",
              "        -3.67027584e-05, -5.25184960e-04, -9.61091895e-04],\n",
              "       ...,\n",
              "       [-1.04166044e-03, -6.22203455e-04, -3.87607251e-03, ...,\n",
              "         9.11139322e-05,  7.08882090e-04, -2.28707732e-04],\n",
              "       [ 3.11329702e-04,  2.05104906e-04,  1.26133242e-03, ...,\n",
              "        -2.76414175e-05, -1.26606635e-03, -6.05603224e-04],\n",
              "       [-1.59055501e-04, -9.82662129e-05, -6.57048516e-04, ...,\n",
              "         1.44252882e-05, -4.10854405e-04, -1.70835075e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKLunqXu40_C",
        "outputId": "0c60f66f-8593-46cc-b59e-10fd85c68cb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.02674556 0.01561039 0.01355649 ... 0.00017731 0.00017714 0.00017709]\n"
          ]
        }
      ]
    }
  ]
}